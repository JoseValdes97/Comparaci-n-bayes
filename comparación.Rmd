---
title: "Ejemplo Puntajes Bayes"
author: José Valdés
output: html_document
---
# Ejemplo: Puntajes de Matemáticas

Los conjuntos de datos de los archivos `SB11_1.txt` contiene una muestra aleatoria del **código del departamento de ubicación del colegio** y el **puntaje de matemáticas de los estudiantes que presentaron la Prueba Saber 11 del primer semestre de 2020**. Estos datos son de carácter público y están disponibles en https://www.icfes.gov.co. 
Se recomienda consultar la *Guía de orientación Saber 11* (Icfes, 2020) para obtener más detalles sobre la prueba. 

La prueba de matemáticas se obtiene mediante un **modelo 3PL** (modelo logístico de 3 parámetros que define la probabilidad de responder correctamente de un individuo, en función de su habilidad, la dificultad del ítem, la discriminación del ítem y el pseudo-azar) y tiene una **escala de 0 a 100** (sin decimales), con **puntaje promedio de 50 puntos** y **desviación estándar 10 puntos** (Icfes, 2018, *Guía de diseño, producción, aplicación y calificación del examen Saber 11*, p. 33).

El objetivo es **construir un modelo predictivo para el puntaje de matemáticas a nivel nacional**, tomando como datos de entrenamiento (*training data*) los resultados del primer semestre de 2020, con el fin de **hacer inferencias sobre la población de estudiantes tanto a nivel nacional como departamental**. Por lo tanto, se toma como variable de agrupamiento el departamento de ubicación del colegio del estudiante. El *Diccionario de variables Saber 11* contiene la información detallada sobre las variables de las bases de datos.


## Estructura de los datos


- $y_{i,j}$:       puntaje de matemáticas del estudiante $i$ y en departamento $j$.
- $n_j\,\,$:       número de estudiantes en el departamento $j$.
- $\bar{y}_j\,\,$: promedio muestral del departamento $j$.
- $s^2_j\,\,$:     varianza muestral del departamento $j$.  

Vamos a traer los datos y las librerias necesarias pal camello xD  
```{r}
# paquetes
#install.packages("dplyr")
#install.packages("ggplot2")
#library(dplyr)
#library(ggplot2)
# datos
SB11_1 <- read.csv("SB11_1_muestra.txt", sep = "", fileEncoding = "UTF-8")
dim(SB11_1)
```
Ahora teniendo en cuenta la siguiente codificación tenemos que:  
```{r}
# Evita tener prolemas al ejercutar funiones de la libreria
suppressMessages(library(dplyr))
# codigo departamentos
codigo <- c(5, 8, 11, 13, 15, 17, 18, 19, 20, 23, 25, 27, 41, 44, 47, 50, 52, 54, 63, 66, 68, 70, 73, 76, 81, 85, 86, 88, 91, 
            94, 95, 97, 99)
nombre <- c("ANTIOQUIA", "ATLANTICO", "BOGOTA", "BOLIVAR", "BOYACA", "CALDAS", "CAQUETA", "CAUCA", "CESAR", "CORDOBA", "CUNDINAMARCA", "CHOCO", "HUILA",
             "LA GUAJIRA", "MAGDALENA", "META", "NARINO", "N. SANTANDER", "QUINDIO", "RISARALDA", "SANTANDER", "SUCRE", "TOLIMA", "VALLE DEL CAUCA", 
             "ARAUCA", "CASANARE", "PUTUMAYO", "SAN ANDRES", "AMAZONAS", "GUAINIA", "GUAVIARE", "VAUPES", "VICHADA")
deptos <- data.frame(codigo, nombre)
# base de datos con nombres
SB11_1 <- left_join(x = SB11_1, y = deptos, by = "codigo")
# numero de estudiantes por departamento
table(SB11_1$nombre)
# remover departamentos con un solo estudiante
SB11_1 <- SB11_1[SB11_1$nombre != "ARAUCA",]
table(SB11_1$nombre)
```
Número  de grupos $m$ y número de indiviudos $n$
```{r}
# m: numero de grupos (departamentos)
m <- length(table(SB11_1$codigo))
m
# n: numero de individuos (estudiantes)
n <- sum(table(SB11_1$codigo))
n
```
Para poder tener la respuesta por grupos haremos los siguientes arreglos  
```{r}
# y  : puntajes de los estudiantes (c)
y  <- SB11_1$puntaje
# Y  : puntajes de los estudiantes (list)
Y  <- vector(mode = "list", length = m)
# g  : identificador secuencial de los departamentos (c)
g  <- rep(NA, n)
# respuestas por grupos
for (j in 1:m) {
    idx <- SB11_1$codigo == unique(SB11_1$codigo)[j]
    g[idx] <- j
    # almacena en una lista los datos por grupo
    Y[[j]] <- y[idx]
}
```
Ahora tendremos una tabla con los datos que necesitamos por grupo
```{r}
# Evita tener prolemas al ejercutar funiones de la libreria
suppressMessages(library(dplyr))
# tabla
estadisticos <- SB11_1 %>% 
                group_by(codigo) %>% 
                summarise(codigo = unique(codigo), nombre = unique(nombre), nj = n(), yb = mean(puntaje), s2 = var(puntaje))
estadisticos
# nj : numero de estudiantes en cada departamento (c)
nj <- estadisticos$nj
nj
# yb : promedios de los puntajes (c)
yb <- estadisticos$yb
yb
# s2 : varianzas de los puntajes (c)
s2 <- estadisticos$s2
s2
```
## Análisis exploratorio  

Haremos un ranking de mayor promedio por grupo a menor

```{r, fig.width=8, fig.height=10, fig.align='center'}
# representacion de los puntajes brutos
par(mfrow = c(1,1), mar = c(4,10,1.5,1), mgp = c(2.5,0.75,0))
plot(x = c(0,100), y = c(1,m), type = "n", xlab = "Puntaje", ylab = "", main = "Ranking (promedio muestral)", yaxt = "n")
abline(h = 1:m, col = "lightgray", lwd = 1)
abline(v = 50,col = "gray", lwd = 3)
for (l in 1:m) {
  j <- order(yb)[l]
  points(x = Y[[j]], y = rep(l, nj[j]), pch = 16, cex = 0.4)
}
lines(x = yb[order(yb)], y = 1:m, type = "p", col = 4, pch = 16, cex = 1.1)
lines(x = yb[order(yb)], y = 1:m, type = "l", col = adjustcolor(4, 0.3))
axis(side = 2, at = 1:m, labels = estadisticos$nombre[order(yb)], las = 2)
```
viendo gráficas para entender la distribución de los promedios
```{r, fig.width=10, fig.height=5, fig.align='center'}
par(mfrow = c(1,2), mar = c(3,3,1,1), mgp = c(1.75,0.75,0)) 
hist(yb, freq = F, main = "", xlab = "Promedio", ylab = "Densidad", border = 4, col = adjustcolor(4, 0.3))
abline(v = mean(y), col = "gray", lwd = 3)
plot(nj, yb, xlab = "Tamano del grupo", ylab = "Promedio", pch = 16, cex = 1.2, col = adjustcolor(4, 0.6))
abline(h = mean(y), col = "gray", lwd = 3)
```

## Distribución previa


Teniendo en cuenta la información de la prueba, el modelo se ajusta utilizando los siguientes hiperparámetros: 
$$
\mu_0 = 50\,,\qquad
\gamma^2_0 = 25\,,\qquad
\eta_0 = 1\,,\qquad
\tau^2_0 = 100\,,\qquad
\nu_0 = 1\,,\qquad
\sigma^2_0 = 100\,.
$$


## Ajuste del modelo

Se crea una función que permite al macenar el  "Muestreador de gibbs" MCMC

```{r}
# algoritmo
MCMC <- function(B, nj, yb, s2) {
  # tamaños
  n <- sum(nj) # de la muestra
  m <- length(nj) # Cantidad de grupos
  # hiperparametros
  mu0  <- 50 
  g20  <- 25
  eta0 <- 1  
  t20  <- 100
  nu0  <- 1  
  s20  <- 100
  # valores iniciales (bayes empirico)
  theta <- yb
  sig2  <- mean(s2)
  mu    <- mean(theta)
  tau2  <- var(theta)
  # almacenamiento de los thetas
  THETA <- matrix(data = NA, nrow = B, ncol = m+3)
  #almacenamiento log-verosimilitud para la convergancia
  LL <- matrix(data = NA, nrow = B, ncol = 1)
  # cadena
  for (b in 1:B) {
    # actualizar theta
    #vtheta <- 1/(1/tau2 + nj/sig2)
    theta  <- rnorm(n = m, mean = (1/(1/tau2 + nj/sig2))*(mu/tau2 + nj*yb/sig2), sd = sqrt(1/(1/tau2 + nj/sig2)))
    # actualizar sigma^2
    sig2 <- 1/rgamma(n = 1, shape = 0.5*(nu0 + n), rate = 0.5*(nu0*s20 + sum((nj-1)*s2 + nj*(yb - theta)^2)))
    # actualizar mu
    #vmu <- 1/(1/g20 + m/tau2)
    mu  <- rnorm(n = 1, mean = (1/(1/g20 + m/tau2))*(mu0/g20 + m*mean(theta)/tau2), sd = sqrt(1/(1/g20 + m/tau2))) 
    # actualizar tau^2
    tau2 <- 1/rgamma(n = 1, shape = 0.5*(eta0 + m), rate = 0.5*(eta0*t20 + (m-1)*var(theta) + m*(mean(theta) - mu)^2))
    # almacenar valores
    THETA[b,] <- c(theta, sig2, mu, tau2)
    # log-verosimilitud
    LL[b] <- sum(dnorm(x = y, mean = rep(theta, nj), sd = sqrt(sig2), log = T))
  }
  # fin de la cadena
  # salida
  # nombres en las matrices de almacenamiento
  colnames(THETA) <- c(paste0("theta",1:m), "sig2", "mu", "tau2")
  colnames(LL) <- c("ll")
  # crear el data frame
  THETA <- as.data.frame(THETA)
  LL    <- as.data.frame(LL)
  # dar como salida una lista conlos data frame
  return(list(THETA = THETA, LL = LL))
}
```

ahora ejecutamos el modelo 
```{r}
#install.packages("tictoc")
# ajuste del modelo
tictoc::tic()
set.seed(2001)
cadena1 <- MCMC(B = 10000, nj, yb, s2)
tictoc::toc()
```
Ver los primeros resultados
```{r}
# muestras de la posterior
head(cadena1$THETA)
```

## Convergencia
```{r, fig.width=10, fig.height=7, fig.align='center'}
# cadenas
par(mfrow = c(2,2), mar = c(2.75,2.75,0.5,0.5), mgp = c(1.7,0.7,0))
plot(cadena1$LL$ll,      type = "p", pch = ".", cex = 1.1, xlab = "Iteracion", ylab = "Log-verosimilitud")
plot(cadena1$THETA$sig2, type = "p", pch = ".", cex = 1.1, xlab = "Iteracion", ylab = expression(sigma^2))
plot(cadena1$THETA$mu,   type = "p", pch = ".", cex = 1.1, xlab = "Iteracion", ylab = expression(mu))
plot(cadena1$THETA$tau2, type = "p", pch = ".", cex = 1.1, xlab = "Iteracion", ylab = expression(tau^2))
```

tamaño efectivod de muestra para $cadena1$

```{r}
#install.packages("coda")
# tamaños efectivos de muestra
neff_SMT <- coda::effectiveSize(cadena1$THETA[,m+(1:3)])
neff_SMT
neff_THETA <- coda::effectiveSize(cadena1$THETA[,1:m])
summary(neff_THETA)
```
errores estandar de MC para $cadena1$
```{r}
# errores estandar de MC
round(apply(X = cadena1$THETA[,m+(1:3)], MARGIN = 2, FUN = sd)/sqrt(neff_SMT), 3)
round(summary(apply(X = cadena1$THETA[,1:m], MARGIN = 2, FUN = sd)/sqrt(neff_THETA)), 3)
```

### autocorrealaciones
```{r, fig.width = 7, fig.height = 3.5, fig.align='center'}
# autocorrelaciones
par(mfrow = c(1,2), mar = c(2.75,2.75,0.5,0.5), mgp = c(1.7,0.7,0))
acf(cadena1$THETA$mu,   main = expression(mu))
acf(cadena1$THETA$tau2, main = expression(tau^2))
```